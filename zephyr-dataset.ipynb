{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -e ./sparseml[transformers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"HuggingFaceH4/ultrachat_200k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92214c8c78b643279abd69cf61962a6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model_id = \"HuggingFaceH4/mistral-7b-sft-beta\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{% for message in messages %}\n",
      "{% if message['role'] == 'user' %}\n",
      "{{ '<|user|>\n",
      "' + message['content'] + eos_token }}\n",
      "{% elif message['role'] == 'system' %}\n",
      "{{ '<|system|>\n",
      "' + message['content'] + eos_token }}\n",
      "{% elif message['role'] == 'assistant' %}\n",
      "{{ '<|assistant|>\n",
      "'  + message['content'] + eos_token }}\n",
      "{% endif %}\n",
      "{% if loop.last and add_generation_prompt %}\n",
      "{{ '<|assistant|>' }}\n",
      "{% endif %}\n",
      "{% endfor %}\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.chat_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[\"train_sft\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "def add_system_prompt(batch):\n",
    "    system_prompt = {\n",
    "        \"content\": \"You are a friendly chatbot\",\n",
    "        \"role\": \"system\"\n",
    "    }\n",
    "\n",
    "    updated_messages = []\n",
    "    for element in batch[\"messages\"]:\n",
    "        updated_messages.append([system_prompt] + element)\n",
    "\n",
    "    return {\"messages_with_sys_prompt\": updated_messages}\n",
    "\n",
    "dataset = dataset.map(\n",
    "    add_system_prompt,\n",
    "    batched=True,\n",
    "    num_proc=32,\n",
    "    batch_size=1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "from typing import List, Union, Any, Dict\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "class DataCollatorForChatLM(DataCollatorForLanguageModeling):\n",
    "    def __init__(\n",
    "        self,\n",
    "        response_template: List[int],\n",
    "        instruction_template: List[int],\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(*args, mlm=False, **kwargs)\n",
    "\n",
    "        self.instruction_token_ids = instruction_template\n",
    "        self.response_token_ids = response_template\n",
    "        self.ignore_index = -100\n",
    "\n",
    "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
    "        batch = super().torch_call(examples)\n",
    "\n",
    "        for i in range(len(examples)):\n",
    "            response_token_ids_idxs = []\n",
    "            human_token_ids_idxs = []\n",
    "\n",
    "            for assistant_idx in np.where(batch[\"labels\"][i] == self.response_token_ids[0])[0]:\n",
    "                # find the indexes of the start of a response.\n",
    "                if (\n",
    "                    self.response_token_ids\n",
    "                    == batch[\"labels\"][i][assistant_idx : assistant_idx + len(self.response_token_ids)].tolist()\n",
    "                ):\n",
    "                    response_token_ids_idxs.append(assistant_idx + len(self.response_token_ids))\n",
    "\n",
    "            if len(response_token_ids_idxs) == 0:\n",
    "                warnings.warn(\n",
    "                    f\"Could not find response key `{self.response_token_ids}` in the \"\n",
    "                    f'following instance: {self.tokenizer.decode(batch[\"input_ids\"][i])} '\n",
    "                    f\"This instance will be ignored in loss calculation. \"\n",
    "                    f\"Note, if this happens often, consider increasing the `max_seq_length`.\"\n",
    "                )\n",
    "                batch[\"labels\"][i, :] = self.ignore_index\n",
    "\n",
    "            human_token_ids = self.instruction_token_ids\n",
    "            for human_idx in np.where(batch[\"labels\"][i] == human_token_ids[0])[0]:\n",
    "                # find the indexes of the start of a human answer.\n",
    "                if human_token_ids == batch[\"labels\"][i][human_idx : human_idx + len(human_token_ids)].tolist():\n",
    "                    human_token_ids_idxs.append(human_idx)\n",
    "\n",
    "            if len(human_token_ids_idxs) == 0:\n",
    "                warnings.warn(\n",
    "                    f\"Could not find instruction key `{self.instruction_token_ids}` in the \"\n",
    "                    f'following instance: {self.tokenizer.decode(batch[\"input_ids\"][i])} '\n",
    "                    f\"This instance will be ignored in loss calculation. \"\n",
    "                    f\"Note, if this happens often, consider increasing the `max_seq_length`.\"\n",
    "                )\n",
    "                batch[\"labels\"][i, :] = self.ignore_index\n",
    "\n",
    "            for idx, (start, end) in enumerate(zip(human_token_ids_idxs, response_token_ids_idxs)):\n",
    "                print(f\"start = {start} / end = {end}\")\n",
    "                assert start < end\n",
    "                # Make pytorch loss function ignore all non response tokens\n",
    "                if idx != 0:\n",
    "                    batch[\"labels\"][i, start:end] = self.ignore_index\n",
    "                else:\n",
    "                    batch[\"labels\"][i, :end] = self.ignore_index\n",
    "            \n",
    "            # assert follows user // assistant back + forth with equal number of query // response pairs\n",
    "            assert len(response_token_ids_idxs) == len(human_token_ids_idxs)\n",
    "            print(human_token_ids_idxs[0])\n",
    "            # mask out everything before the first user prompt (i.e. the system prompt)\n",
    "            batch[\"labels\"][i, :human_token_ids_idxs[0]] = self.ignore_index\n",
    "            \n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28789, 28766, 489, 11143, 28766, 28767]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|assistant|>'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response_template_ids = tokenizer.encode(\"/n<|assistant|>\", add_special_tokens=False)[2:]\n",
    "print(response_template_ids)\n",
    "tokenizer.decode(response_template_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28789, 28766, 1838, 28766, 28767]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'<|user|>'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instruction_template_ids = tokenizer.encode(\"/n<|user|>\", add_special_tokens=False)[2:]\n",
    "print(instruction_template_ids)\n",
    "tokenizer.decode(instruction_template_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from trl import DataCollatorForCompletionOnlyLM\n",
    "\n",
    "# collator = DataCollatorForChatLM(\n",
    "collator = DataCollatorForCompletionOnlyLM(\n",
    "    response_template=response_template_ids,\n",
    "    instruction_template=instruction_template_ids,\n",
    "    tokenizer=tokenizer,\n",
    ")\n",
    "\n",
    "def apply_chat_template(tokenizer, messages_col, batch):\n",
    "    strs = []\n",
    "    for example in batch[messages_col]:\n",
    "        strs.append(tokenizer.apply_chat_template(example, tokenize=False))\n",
    "\n",
    "    return strs\n",
    "\n",
    "chat_formatting_func = partial(apply_chat_template, tokenizer, \"messages_with_sys_prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255170e3f66046408b62d62c3b85e293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=32):   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1387: FutureWarning: promote has been superseded by mode='default'.\n",
      "  return cls._concat_blocks(pa_tables_to_concat_vertically, axis=0)\n",
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n"
     ]
    }
   ],
   "source": [
    "def tokenize(element):\n",
    "    chat_format = chat_formatting_func(element)\n",
    "\n",
    "    outputs = tokenizer(\n",
    "        chat_format,\n",
    "        truncation=True,\n",
    "        padding=False,\n",
    "        max_length=2048,\n",
    "        return_overflowing_tokens=False,\n",
    "        return_length=False,\n",
    "    )\n",
    "\n",
    "    return {\"input_ids\": outputs[\"input_ids\"], \"attention_mask\": outputs[\"attention_mask\"], \"chat_format\": chat_format}\n",
    "\n",
    "tokenized_dataset = dataset.select(range(10000)).map(\n",
    "    tokenize,\n",
    "    batched=True,\n",
    "    num_proc=32,\n",
    "    batch_size=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset_removed = tokenized_dataset.remove_columns([col for col in tokenized_dataset.column_names if col not in [\"input_ids\", \"attention_mask\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataloader_params = {\n",
    "    \"batch_size\": 1,\n",
    "    \"collate_fn\": collator,\n",
    "}\n",
    "\n",
    "dataloader = DataLoader(tokenized_dataset_removed, **dataloader_params)\n",
    "\n",
    "batch = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([    1,   523, 28766,  6574, 28766, 28767,    13,  1976,   460,   264,\n",
      "        10131, 10706, 10093,     2, 28705,    13, 28789, 28766,  1838, 28766,\n",
      "        28767,    13, 18171, 11382,  5580,   298,  4211, 28733,  5527, 18978,\n",
      "          325,  1146, 13532,   495, 28705, 28784, 28723, 28734, 28806, 28725,\n",
      "         8337,  1380, 28705, 28781, 28723, 28734, 28806, 28725,  2316,   455,\n",
      "          897, 28705, 28770, 28723, 28734, 28806,  6372,  1798, 28705, 28750,\n",
      "        28723, 28734, 28806, 28725,   351,   598, 16712, 28705, 28782, 28723,\n",
      "        28734, 28806,   609,  1824,  7335,  2751,   837,   315,  1413, 28804,\n",
      "           13,  2486,   574, 27395,  6718,   567, 22114, 28715, 27395, 12458,\n",
      "        28725,   368,   541,  5061,  1347,   272, 13461,  3469,   302,   264])\n",
      "<|system|>\n",
      "You are a friendly chatbot</s>\n",
      "<|user|>\n",
      "These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\n",
      "On your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\n",
      "Your Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\n",
      "Does this feature apply to all sections of the theme or just specific ones as listed in the text material?</s>\n",
      "<|assistant|>\n",
      "This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.</s>\n",
      "<|user|>\n",
      "Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?</s>\n",
      "<|assistant|>\n",
      "Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\n",
      "\n",
      "1. Log in to your Shopify account and go to your Online Store.\n",
      "2. Click on Customize theme for the section-based theme you are using.\n",
      "3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\n",
      "4. With the section open, click on the section's setting (gear) icon in the top-left corner.\n",
      "5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\n",
      "6. If available, select 'Show secondary image on hover'.\n",
      "7. Save the changes and preview the Collection/Featured Collection page to see the effect.\n",
      "\n",
      "If you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.</s>\n",
      "<|user|>\n",
      "Can you provide me with a link to the documentation for my theme?</s>\n",
      "<|assistant|>\n",
      "I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.</s>\n",
      "<|user|>\n",
      "Can you confirm if this feature also works for the Quick Shop section of my theme?</s>\n",
      "<|assistant|>\n",
      "The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\n",
      "\n",
      "1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.tensor(tokenized_dataset[0][\"input_ids\"][:100]))\n",
    "print(tokenized_dataset[0][\"chat_format\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 28705, 13, 28789, 28766, 489, 11143, 28766, 28767, 13, 3260, 4480, 865, 15588, 298, 13079, 6718, 304, 22114, 28715, 27395, 12458, 302, 272, 4211, 28733, 5527, 18978, 9206, 297, 272, 2245, 3388, 28723]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"\\n<|assistant|>\\nThis feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 28705, 13, 3260, 4480, 865, 15588, 298, 13079, 6718]\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.encode(\"\\nThis feature only applies to Collection pages\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThis feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.</s>'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode([13,  3260,  4480,   865, 15588,   298, 13079,  6718,   304, 22114, 28715, 27395, 12458,   302,   272,  4211, 28733,  5527, 18978,  9206,   297,   272,  2245,  3388, 28723,     2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = batch[\"labels\"][0]\n",
    "\n",
    "for idx, label in enumerate(labels):\n",
    "    if label == -100:\n",
    "        labels[idx]=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|system|>\n",
      "You are a friendly chatbot</s>\n",
      "<|user|>\n",
      "These instructions apply to section-based themes (Responsive 6.0+, Retina 4.0+, Parallax 3.0+ Turbo 2.0+, Mobilia 5.0+). What theme version am I using?\n",
      "On your Collections pages & Featured Collections sections, you can easily show the secondary image of a product on hover by enabling one of the theme's built-in settings!\n",
      "Your Collection pages & Featured Collections sections will now display the secondary product image just by hovering over that product image thumbnail.\n",
      "Does this feature apply to all sections of the theme or just specific ones as listed in the text material?</s>\n",
      "<|assistant|>\n",
      "This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.</s>\n",
      "<|user|>\n",
      "Can you guide me through the process of enabling the secondary image hover feature on my Collection pages and Featured Collections sections?</s>\n",
      "<|assistant|>\n",
      "Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\n",
      "\n",
      "1. Log in to your Shopify account and go to your Online Store.\n",
      "2. Click on Customize theme for the section-based theme you are using.\n",
      "3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\n",
      "4. With the section open, click on the section's setting (gear) icon in the top-left corner.\n",
      "5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\n",
      "6. If available, select 'Show secondary image on hover'.\n",
      "7. Save the changes and preview the Collection/Featured Collection page to see the effect.\n",
      "\n",
      "If you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.</s>\n",
      "<|user|>\n",
      "Can you provide me with a link to the documentation for my theme?</s>\n",
      "<|assistant|>\n",
      "I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.</s>\n",
      "<|user|>\n",
      "Can you confirm if this feature also works for the Quick Shop section of my theme?</s>\n",
      "<|assistant|>\n",
      "The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\n",
      "\n",
      "1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.</s>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_dataset[0][\"chat_format\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n",
      "This feature only applies to Collection pages and Featured Collections sections of the section-based themes listed in the text material.<s> \n",
      "<s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n",
      "Sure, here are the steps to enable the secondary image hover feature on your Collection pages and Featured Collections sections:\n",
      "\n",
      "1. Log in to your Shopify account and go to your Online Store.\n",
      "2. Click on Customize theme for the section-based theme you are using.\n",
      "3. Navigate to the Collection pages or Featured Collections section where you want to enable the secondary image hover feature.\n",
      "4. With the section open, click on the section's setting (gear) icon in the top-left corner.\n",
      "5. In the settings panel that appears, look for an option labeled 'Image display' or 'Image hover'.\n",
      "6. If available, select 'Show secondary image on hover'.\n",
      "7. Save the changes and preview the Collection/Featured Collection page to see the effect.\n",
      "\n",
      "If you're having trouble finding the setting, the best thing to do is refer to your theme's documentation, since the location and labeling of settings can vary between themes.<s> \n",
      "<s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n",
      "I don't have access to your store's theme information. However, you can usually find the documentation for your theme by going to the shopify theme store, finding your theme and clicking on the 'support' link located in the bottom right corner of the page. Alternatively, you can do a google search for the name of your theme followed by 'documentation' or 'user guide'.<s> \n",
      "<s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s><s>\n",
      "The secondary image hover feature may or may not work for your Quick Shop section, depending on the configuration of your theme. Some themes include this feature in the Quick Shop section by default, while others may require additional customization. To check if this feature is available for the Quick Shop section of your theme, follow these steps:\n",
      "\n",
      "1. Go to the Quick Shop section where you would like to enable the feature. 2. Click on the Quick Shop settings icon (gear icon) and look for 'Image display' or 'Image hover'. 3. If available, select 'Show secondary image on hover'. 4. Save the changes. If this option is not available in your Quick Shop section settings, you may need to reach out to your theme developer for assistance with customizing your Quick Shop section to include this feature.<s> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rshaw/zephyr-pruning/.venv/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:214: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "\n",
    "sft_trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    train_dataset=dataset.select(range(10000)),\n",
    "    data_collator=collator,\n",
    "    formatting_func=chat_formatting_func,\n",
    "    max_seq_length=2048\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
